# DK Sentinel

Hi, I am Colby Reichenbach. I built this portfolio project to show how I approach a modern Responsible Gaming analyst workflow using SQL-first investigation, auditable AI assistance, and clear human accountability.

## Tooling
`Python` `FastAPI` `DuckDB` `dbt` `SQL` `React` `TypeScript` `Vite` `OpenAI API` `Pytest` `Vitest`

## What I Built
- API-backed analyst workflow: queue -> case detail -> case file -> submission.
- Case status lifecycle logging (`NOT_STARTED`, `IN_PROGRESS`, `SUBMITTED`).
- SQL drafting and execution workflow with explicit analyst review.
- Prompt router (`SQL_DRAFT`, `REGULATORY_CONTEXT`, `EXTERNAL_CONTEXT`, `GENERAL_ANALYSIS`) with route/tool logging.
- Snowflake syntax guardrails for generated SQL plus schema-aware prompting.
- State-specific trigger checks for MA/NJ/PA with deterministic logs.
- Static demo mode and live API mode with explicit separation.
- PDF case export from the case file workflow.

## Why This Matters To Me As An Analyst
I treat AI as an analyst accelerator, not an analyst replacement.
- Less time writing repetitive SQL.
- More time validating evidence quality, contradiction checks, and intervention decisions.
- Better governance because prompts, outputs, query logs, and decisions are all reviewable.

## HITL (Human In The Loop) In This Project
- AI never auto-submits decisions.
- Final intervention and rationale are analyst-owned.
- SQL is generated by LLM, then reviewed, then executed in read-only mode.
- Prompt routing and outputs are logged for audit and replay.

## Live vs Static Demo
### Live mode (`VITE_DATA_MODE=api`)
- Frontend reads queue/case/audit/analytics from backend endpoints.
- Opening a case can trigger backend trigger-check execution (with cache behavior in API).

### Static mode (`VITE_DATA_MODE=static`)
- Frontend reads from exported `frontend/public/demo/*` fixtures.
- Trigger-check behavior is replayed from static fixtures and stored in browser state.

## Current Limitations (Truthful Scope)
- All player data is synthesized; it is not production operator data.
- Synthetic behavior cannot fully reproduce real player randomness or all edge-case context.
- Model and analyst outputs can inherit bias from synthetic distributions.
- Regulatory and external-context routes are generic LLM-context patterns; they are not backed by a production legal knowledge base in this repo.
- External event context ingestion (news/social/schedule feeds) is not implemented in this codebase.

## Ideas I Would Implement Next In Production
- Internal regulatory knowledge retrieval (state statutes, policy memos, legal approvals).
- Event-aware context retrieval (sports calendars, media context, market-specific spikes).
- Example analyst prompt: "Why did tennis volume increase during these dates?"
  - Desired response pattern: identify known event window (for example Wimbledon), key match windows, and expected market-drift effects.
- Governance workflow where legal/compliance receives flagged regulatory summaries for review.

## Modern Analyst Point Of View
I do not see analyst work as spreadsheet triage. I see it as:
- automated evidence retrieval,
- governed AI assistance,
- and analyst judgment focused on outcomes and risk controls.

## Quick Start
### Live mode
```bash
pip install -r requirements.txt
python scripts/seed_demo_db.py --completed 20 --in-progress 2

# terminal 1
cd backend && uvicorn main:app --reload --port 8000

# terminal 2
cd frontend && npm install && npm run dev
```

### Static mode
```bash
./scripts/build_static_demo.sh
cd frontend && npm install && npm run dev:static
```

## Docs Map
- `docs/TECHNICAL_DEEP_DIVE.md`
- `docs/ANALYST_PLAYBOOK.md`
- `docs/LLM_INTEGRATION.md`
- `docs/PROD_PARITY_CHECKLIST.md`
- `docs/case_reviews/README.md`
